{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30fc31fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c6ba8d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abfb0612",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4148d2cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9284120",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f87f179",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd8aa95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'v1': 'target', 'v2': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f432dbb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                    text\n",
       "count    5572                    5572\n",
       "unique      2                    5158\n",
       "top       ham  Sorry, I'll call later\n",
       "freq     4825                      30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6e0fd58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae354c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ab0b3e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5158</td>\n",
       "      <td>5158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                                               text\n",
       "count    5158                                               5158\n",
       "unique      2                                               5158\n",
       "top       ham  Go until jurong point, crazy.. Available only ...\n",
       "freq     4516                                                  1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12cac425",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5158, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a883c86",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c60c53f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', text)\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)\n",
    "    text_tokens = word_tokenize(text)\n",
    "    text_tokens = [text_token for text_token in text_tokens if text_token.isalpha()]\n",
    "    text_tokens = [text_token.translate(str.maketrans('', '', string.punctuation)) for text_token in text_tokens]\n",
    "    stemmer = PorterStemmer()\n",
    "    text_tokens = [stemmer.stem(text_token) for text_token in text_tokens if not text_token in set(stopwords.words('english'))]\n",
    "    text = ' '.join(text_tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0998911",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3beaf7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri wkli comp win fa cup final tkt may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri wkli comp win fa cup final tkt may ...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4               nah think goe usf live around though  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b72e2c81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['clean_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1b49850",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder().fit(df['target'])\n",
    "y = label_encoder.transform(df['target'])\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fd73a55",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "006c8f31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980176</td>\n",
       "      <td>0.985136</td>\n",
       "      <td>0.982650</td>\n",
       "      <td>3162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891455</td>\n",
       "      <td>0.859688</td>\n",
       "      <td>0.875283</td>\n",
       "      <td>449.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.969538</td>\n",
       "      <td>0.969538</td>\n",
       "      <td>0.969538</td>\n",
       "      <td>0.969538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.935816</td>\n",
       "      <td>0.922412</td>\n",
       "      <td>0.928967</td>\n",
       "      <td>3611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.969144</td>\n",
       "      <td>0.969538</td>\n",
       "      <td>0.969300</td>\n",
       "      <td>3611.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.980176  0.985136  0.982650  3162.000000\n",
       "1              0.891455  0.859688  0.875283   449.000000\n",
       "accuracy       0.969538  0.969538  0.969538     0.969538\n",
       "macro avg      0.935816  0.922412  0.928967  3611.000000\n",
       "weighted avg   0.969144  0.969538  0.969300  3611.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9094b528",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.968914</td>\n",
       "      <td>0.995572</td>\n",
       "      <td>0.982062</td>\n",
       "      <td>3162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.961326</td>\n",
       "      <td>0.775056</td>\n",
       "      <td>0.858200</td>\n",
       "      <td>449.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.968153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.965120</td>\n",
       "      <td>0.885314</td>\n",
       "      <td>0.920131</td>\n",
       "      <td>3611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.967970</td>\n",
       "      <td>0.968153</td>\n",
       "      <td>0.966661</td>\n",
       "      <td>3611.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.968914  0.995572  0.982062  3162.000000\n",
       "1              0.961326  0.775056  0.858200   449.000000\n",
       "accuracy       0.968153  0.968153  0.968153     0.968153\n",
       "macro avg      0.965120  0.885314  0.920131  3611.000000\n",
       "weighted avg   0.967970  0.968153  0.966661  3611.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ed5cd04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20730cb2",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 21:43:19.406032: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import  Dense\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b347f3f5-c3e6-44df-bae9-41330dfd1350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-08 21:43:21.435310: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "304d6370-b0e4-48a6-9550-df2069be3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(X_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35f877dd-1829-4e71-ad57-e69ddc2bb3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (1547, 32)                187136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1547, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (1547, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 189,313\n",
      "Trainable params: 189,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb92d18f-29bf-43bd-bc00-226fa881165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 9ms/step - loss: 0.6487 - accuracy: 0.8503 - val_loss: 0.6073 - val_accuracy: 0.8774\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5728 - accuracy: 0.8743 - val_loss: 0.5386 - val_accuracy: 0.8774\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.8743 - val_loss: 0.4862 - val_accuracy: 0.8774\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.8743 - val_loss: 0.4481 - val_accuracy: 0.8774\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4351 - accuracy: 0.8743 - val_loss: 0.4207 - val_accuracy: 0.8774\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8743 - val_loss: 0.4009 - val_accuracy: 0.8774\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8743 - val_loss: 0.3864 - val_accuracy: 0.8774\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3808 - accuracy: 0.8743 - val_loss: 0.3757 - val_accuracy: 0.8774\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8743 - val_loss: 0.3673 - val_accuracy: 0.8774\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8743 - val_loss: 0.3606 - val_accuracy: 0.8774\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8743 - val_loss: 0.3551 - val_accuracy: 0.8774\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8743 - val_loss: 0.3503 - val_accuracy: 0.8774\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8743 - val_loss: 0.3459 - val_accuracy: 0.8774\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8743 - val_loss: 0.3418 - val_accuracy: 0.8774\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.8743 - val_loss: 0.3377 - val_accuracy: 0.8774\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8743 - val_loss: 0.3337 - val_accuracy: 0.8774\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3218 - accuracy: 0.8743 - val_loss: 0.3296 - val_accuracy: 0.8774\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8743 - val_loss: 0.3255 - val_accuracy: 0.8774\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3106 - accuracy: 0.8743 - val_loss: 0.3212 - val_accuracy: 0.8774\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.8743 - val_loss: 0.3168 - val_accuracy: 0.8774\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2988 - accuracy: 0.8743 - val_loss: 0.3121 - val_accuracy: 0.8774\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.8743 - val_loss: 0.3074 - val_accuracy: 0.8774\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.8743 - val_loss: 0.3025 - val_accuracy: 0.8774\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2796 - accuracy: 0.8743 - val_loss: 0.2975 - val_accuracy: 0.8774\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2730 - accuracy: 0.8743 - val_loss: 0.2924 - val_accuracy: 0.8774\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2662 - accuracy: 0.8743 - val_loss: 0.2873 - val_accuracy: 0.8774\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2592 - accuracy: 0.8743 - val_loss: 0.2820 - val_accuracy: 0.8774\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2523 - accuracy: 0.8743 - val_loss: 0.2767 - val_accuracy: 0.8774\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.8743 - val_loss: 0.2715 - val_accuracy: 0.8774\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.8743 - val_loss: 0.2663 - val_accuracy: 0.8774\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2316 - accuracy: 0.8743 - val_loss: 0.2610 - val_accuracy: 0.8774\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2248 - accuracy: 0.8762 - val_loss: 0.2559 - val_accuracy: 0.8839\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2181 - accuracy: 0.8780 - val_loss: 0.2509 - val_accuracy: 0.8860\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2116 - accuracy: 0.8808 - val_loss: 0.2459 - val_accuracy: 0.8860\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2051 - accuracy: 0.8909 - val_loss: 0.2410 - val_accuracy: 0.8882\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1988 - accuracy: 0.8983 - val_loss: 0.2362 - val_accuracy: 0.8903\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1927 - accuracy: 0.9122 - val_loss: 0.2316 - val_accuracy: 0.8989\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1867 - accuracy: 0.9196 - val_loss: 0.2272 - val_accuracy: 0.9011\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1809 - accuracy: 0.9224 - val_loss: 0.2229 - val_accuracy: 0.9075\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1753 - accuracy: 0.9279 - val_loss: 0.2188 - val_accuracy: 0.9075\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1699 - accuracy: 0.9316 - val_loss: 0.2145 - val_accuracy: 0.9075\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.9362 - val_loss: 0.2106 - val_accuracy: 0.9075\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1595 - accuracy: 0.9418 - val_loss: 0.2066 - val_accuracy: 0.9118\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9455 - val_loss: 0.2031 - val_accuracy: 0.9118\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1498 - accuracy: 0.9455 - val_loss: 0.1996 - val_accuracy: 0.9118\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1453 - accuracy: 0.9501 - val_loss: 0.1964 - val_accuracy: 0.9161\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9566 - val_loss: 0.1931 - val_accuracy: 0.9140\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9584 - val_loss: 0.1905 - val_accuracy: 0.9161\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9584 - val_loss: 0.1873 - val_accuracy: 0.9183\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1290 - accuracy: 0.9621 - val_loss: 0.1846 - val_accuracy: 0.9204\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.9621 - val_loss: 0.1819 - val_accuracy: 0.9269\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1219 - accuracy: 0.9658 - val_loss: 0.1796 - val_accuracy: 0.9290\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.9667 - val_loss: 0.1772 - val_accuracy: 0.9290\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.9667 - val_loss: 0.1746 - val_accuracy: 0.9312\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9695 - val_loss: 0.1723 - val_accuracy: 0.9333\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.9704 - val_loss: 0.1704 - val_accuracy: 0.9333\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9704 - val_loss: 0.1687 - val_accuracy: 0.9333\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9704 - val_loss: 0.1668 - val_accuracy: 0.9333\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1018 - accuracy: 0.9713 - val_loss: 0.1652 - val_accuracy: 0.9333\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9732 - val_loss: 0.1640 - val_accuracy: 0.9333\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9741 - val_loss: 0.1624 - val_accuracy: 0.9333\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.9741 - val_loss: 0.1610 - val_accuracy: 0.9333\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9760 - val_loss: 0.1601 - val_accuracy: 0.9355\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9750 - val_loss: 0.1587 - val_accuracy: 0.9398\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9769 - val_loss: 0.1579 - val_accuracy: 0.9398\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0871 - accuracy: 0.9760 - val_loss: 0.1566 - val_accuracy: 0.9398\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9760 - val_loss: 0.1554 - val_accuracy: 0.9441\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9787 - val_loss: 0.1544 - val_accuracy: 0.9441\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9815 - val_loss: 0.1536 - val_accuracy: 0.9441\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9815 - val_loss: 0.1528 - val_accuracy: 0.9441\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9815 - val_loss: 0.1518 - val_accuracy: 0.9441\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9815 - val_loss: 0.1510 - val_accuracy: 0.9441\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9815 - val_loss: 0.1496 - val_accuracy: 0.9441\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9824 - val_loss: 0.1493 - val_accuracy: 0.9441\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9824 - val_loss: 0.1487 - val_accuracy: 0.9441\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0719 - accuracy: 0.9824 - val_loss: 0.1485 - val_accuracy: 0.9462\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9834 - val_loss: 0.1480 - val_accuracy: 0.9462\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9834 - val_loss: 0.1468 - val_accuracy: 0.9462\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9834 - val_loss: 0.1462 - val_accuracy: 0.9462\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9834 - val_loss: 0.1455 - val_accuracy: 0.9462\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9843 - val_loss: 0.1451 - val_accuracy: 0.9462\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9843 - val_loss: 0.1446 - val_accuracy: 0.9462\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9843 - val_loss: 0.1445 - val_accuracy: 0.9462\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9843 - val_loss: 0.1441 - val_accuracy: 0.9462\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9843 - val_loss: 0.1438 - val_accuracy: 0.9462\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9843 - val_loss: 0.1434 - val_accuracy: 0.9462\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9852 - val_loss: 0.1421 - val_accuracy: 0.9462\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9843 - val_loss: 0.1412 - val_accuracy: 0.9462\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0579 - accuracy: 0.9852 - val_loss: 0.1413 - val_accuracy: 0.9462\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.9852 - val_loss: 0.1410 - val_accuracy: 0.9462\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9852 - val_loss: 0.1407 - val_accuracy: 0.9462\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9852 - val_loss: 0.1402 - val_accuracy: 0.9505\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9852 - val_loss: 0.1400 - val_accuracy: 0.9505\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0535 - accuracy: 0.9852 - val_loss: 0.1396 - val_accuracy: 0.9505\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9861 - val_loss: 0.1390 - val_accuracy: 0.9505\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9861 - val_loss: 0.1390 - val_accuracy: 0.9505\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9861 - val_loss: 0.1392 - val_accuracy: 0.9505\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9871 - val_loss: 0.1388 - val_accuracy: 0.9505\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9871 - val_loss: 0.1387 - val_accuracy: 0.9505\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9871 - val_loss: 0.1387 - val_accuracy: 0.9505\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9871 - val_loss: 0.1385 - val_accuracy: 0.9505\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9889 - val_loss: 0.1387 - val_accuracy: 0.9505\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9889 - val_loss: 0.1381 - val_accuracy: 0.9505\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0456 - accuracy: 0.9889 - val_loss: 0.1378 - val_accuracy: 0.9505\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9889 - val_loss: 0.1375 - val_accuracy: 0.9505\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0441 - accuracy: 0.9898 - val_loss: 0.1373 - val_accuracy: 0.9505\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9898 - val_loss: 0.1367 - val_accuracy: 0.9505\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9898 - val_loss: 0.1365 - val_accuracy: 0.9505\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9898 - val_loss: 0.1367 - val_accuracy: 0.9505\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 0.9898 - val_loss: 0.1364 - val_accuracy: 0.9505\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0407 - accuracy: 0.9908 - val_loss: 0.1364 - val_accuracy: 0.9505\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9908 - val_loss: 0.1365 - val_accuracy: 0.9505\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9908 - val_loss: 0.1368 - val_accuracy: 0.9505\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9917 - val_loss: 0.1364 - val_accuracy: 0.9505\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9917 - val_loss: 0.1361 - val_accuracy: 0.9505\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9926 - val_loss: 0.1357 - val_accuracy: 0.9505\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9926 - val_loss: 0.1354 - val_accuracy: 0.9505\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9926 - val_loss: 0.1354 - val_accuracy: 0.9505\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9926 - val_loss: 0.1353 - val_accuracy: 0.9505\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9926 - val_loss: 0.1351 - val_accuracy: 0.9505\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9926 - val_loss: 0.1348 - val_accuracy: 0.9505\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9926 - val_loss: 0.1344 - val_accuracy: 0.9505\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9926 - val_loss: 0.1343 - val_accuracy: 0.9505\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 0.9926 - val_loss: 0.1342 - val_accuracy: 0.9505\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9926 - val_loss: 0.1341 - val_accuracy: 0.9505\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0326 - accuracy: 0.9926 - val_loss: 0.1338 - val_accuracy: 0.9505\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9926 - val_loss: 0.1337 - val_accuracy: 0.9505\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9926 - val_loss: 0.1338 - val_accuracy: 0.9505\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0313 - accuracy: 0.9926 - val_loss: 0.1334 - val_accuracy: 0.9527\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9926 - val_loss: 0.1334 - val_accuracy: 0.9527\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0305 - accuracy: 0.9926 - val_loss: 0.1339 - val_accuracy: 0.9527\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9926 - val_loss: 0.1340 - val_accuracy: 0.9548\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9926 - val_loss: 0.1338 - val_accuracy: 0.9548\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9926 - val_loss: 0.1338 - val_accuracy: 0.9548\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.1340 - val_accuracy: 0.9548\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 0.1336 - val_accuracy: 0.9548\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9926 - val_loss: 0.1332 - val_accuracy: 0.9548\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9926 - val_loss: 0.1332 - val_accuracy: 0.9548\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9926 - val_loss: 0.1329 - val_accuracy: 0.9548\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9945 - val_loss: 0.1326 - val_accuracy: 0.9548\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9945 - val_loss: 0.1327 - val_accuracy: 0.9548\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9945 - val_loss: 0.1329 - val_accuracy: 0.9548\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9945 - val_loss: 0.1332 - val_accuracy: 0.9548\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 0.9945 - val_loss: 0.1330 - val_accuracy: 0.9548\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9945 - val_loss: 0.1330 - val_accuracy: 0.9548\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9954 - val_loss: 0.1323 - val_accuracy: 0.9548\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9548\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9548\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9548\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9963 - val_loss: 0.1329 - val_accuracy: 0.9548\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9963 - val_loss: 0.1326 - val_accuracy: 0.9548\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9963 - val_loss: 0.1326 - val_accuracy: 0.9548\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9963 - val_loss: 0.1327 - val_accuracy: 0.9548\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9963 - val_loss: 0.1325 - val_accuracy: 0.9548\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9548\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9963 - val_loss: 0.1327 - val_accuracy: 0.9548\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9548\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 0.9963 - val_loss: 0.1325 - val_accuracy: 0.9548\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9963 - val_loss: 0.1328 - val_accuracy: 0.9548\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 0.1321 - val_accuracy: 0.9548\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9548\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9548\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9963 - val_loss: 0.1321 - val_accuracy: 0.9548\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9963 - val_loss: 0.1320 - val_accuracy: 0.9548\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9963 - val_loss: 0.1321 - val_accuracy: 0.9548\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9963 - val_loss: 0.1323 - val_accuracy: 0.9548\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0201 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9963 - val_loss: 0.1321 - val_accuracy: 0.9548\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9963 - val_loss: 0.1323 - val_accuracy: 0.9548\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9963 - val_loss: 0.1323 - val_accuracy: 0.9548\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0188 - accuracy: 0.9963 - val_loss: 0.1321 - val_accuracy: 0.9548\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 0.1323 - val_accuracy: 0.9548\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9548\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 0.1326 - val_accuracy: 0.9548\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.1323 - val_accuracy: 0.9548\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0181 - accuracy: 0.9963 - val_loss: 0.1318 - val_accuracy: 0.9548\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9963 - val_loss: 0.1319 - val_accuracy: 0.9548\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.1320 - val_accuracy: 0.9548\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9963 - val_loss: 0.1320 - val_accuracy: 0.9548\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.1320 - val_accuracy: 0.9548\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 0.1321 - val_accuracy: 0.9548\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9963 - val_loss: 0.1323 - val_accuracy: 0.9548\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9963 - val_loss: 0.1323 - val_accuracy: 0.9548\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.1322 - val_accuracy: 0.9548\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.1323 - val_accuracy: 0.9548\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.1325 - val_accuracy: 0.9548\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.1326 - val_accuracy: 0.9548\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.1324 - val_accuracy: 0.9548\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 0.1326 - val_accuracy: 0.9548\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.1331 - val_accuracy: 0.9548\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.1330 - val_accuracy: 0.9548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fddc0090160>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b1a16af-7d20-4a78-8700-502fa18f3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat = [0 if val < 0.5 else 1 for val in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8a588fe-b747-41d2-bc30-4ab78409098f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.971225</td>\n",
       "      <td>0.992726</td>\n",
       "      <td>0.981858</td>\n",
       "      <td>3162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.939314</td>\n",
       "      <td>0.792873</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>449.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.967876</td>\n",
       "      <td>0.967876</td>\n",
       "      <td>0.967876</td>\n",
       "      <td>0.967876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.955270</td>\n",
       "      <td>0.892800</td>\n",
       "      <td>0.920881</td>\n",
       "      <td>3611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.967257</td>\n",
       "      <td>0.967876</td>\n",
       "      <td>0.966694</td>\n",
       "      <td>3611.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.971225  0.992726  0.981858  3162.000000\n",
       "1              0.939314  0.792873  0.859903   449.000000\n",
       "accuracy       0.967876  0.967876  0.967876     0.967876\n",
       "macro avg      0.955270  0.892800  0.920881  3611.000000\n",
       "weighted avg   0.967257  0.967876  0.966694  3611.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_test, y_hat, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90c40b89-c10c-4e10-ae5d-3219be319ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11296577006578445, 0.9678759574890137]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "729ed1f5-e66f-4a8c-ad7f-6e6cbabc174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (4.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (1.22.2)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (2.27.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (0.9.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (2022.1.18)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (0.12.1)\n",
      "Requirement already satisfied: torch<1.12,>=1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[torch]) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers[torch]) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging>=20.0->transformers[torch]) (3.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[torch]) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[torch]) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[torch]) (2.0.12)\n",
      "Requirement already satisfied: transformers[tf-cpu] in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (4.21.3)\n",
      "Requirement already satisfied: filelock in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (2022.1.18)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (1.22.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (0.9.1)\n",
      "Requirement already satisfied: tensorflow-text in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (2.10.0)\n",
      "Requirement already satisfied: onnxconverter-common in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (1.12.2)\n",
      "Requirement already satisfied: tf2onnx in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (1.8.4)\n",
      "Requirement already satisfied: tensorflow-cpu>=2.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from transformers[tf-cpu]) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers[tf-cpu]) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging>=20.0->transformers[tf-cpu]) (3.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (1.48.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (1.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (2.0.7)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (0.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (14.0.6)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-cpu>=2.3->transformers[tf-cpu]) (59.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow-cpu>=2.3->transformers[tf-cpu]) (0.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (2.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (2.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[tf-cpu]) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[tf-cpu]) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[tf-cpu]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->transformers[tf-cpu]) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow-cpu>=2.3->transformers[tf-cpu]) (2.1.1)\n",
      "Requirement already satisfied: onnx in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from onnxconverter-common->transformers[tf-cpu]) (1.12.0)\n",
      "Requirement already satisfied: tensorflow<2.11,>=2.10.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-text->transformers[tf-cpu]) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow-text->transformers[tf-cpu]) (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers[torch]\n",
    "# !pip install transformers[tf-cpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a4ab831-faf4-4caf-b251-c138e4c5d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['clean_text'], df['target'], stratify=df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7253dc58-c4d6-476a-a94c-eadc9a99dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install simpletransformers\n",
    "# !pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5cb15a99-94d3-4f91-b54a-e20f2b7c177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24911ea1-7d72-4515-a6e4-670e7bd9c9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel('xlnet', 'xlnet-base-cased', use_cuda=False, args={'num_train_epochs':4, 'train_batch_size':32, 'max_seq_length':128}) # You can set class weights by using the optional weight argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f53b9f1-232c-4d76-966f-81f3cc2b35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(X_train)\n",
    "train_df['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb256c-3c3b-4c9d-98cf-727b0c9050bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py:601: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e21bd950494e46bc0127d155f0df46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1547 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2cccd-4d30-4861-928a-c59b64e35463",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(X_test)\n",
    "eval_df['target'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322ef00-6e0c-48a3-9d53-a6126c6b9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df, acc=accuracy_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
